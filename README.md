# Ingelect ğŸ¤– - Engineer Assistant

Sistema de asistente inteligente basado en RAG (Retrieval-Augmented Generation) que permite consultar documentos tÃ©cnicos mediante un chat interactivo construido con Streamlit y LangGraph.

## ğŸš€ CaracterÃ­sticas

- **Arquitectura Multi-Agente**: Sistema supervisor que delega consultas a agentes especializados
- **RAG con FAISS**: BÃºsqueda semÃ¡ntica eficiente en documentos PDF
- **Interfaz Streamlit**: UI interactiva y fÃ¡cil de usar
- **Modular y Escalable**: CÃ³digo organizado en mÃ³dulos independientes
- **ConfiguraciÃ³n Flexible**: ParÃ¡metros ajustables de chunking para optimizar resultados

## ğŸ“‹ Requisitos

- Python 3.12+
- API Keys:
  - Google API Key (para Gemini)
  - Cohere API Key (para embeddings)

## ğŸ› ï¸ InstalaciÃ³n

1. **Clonar el repositorio**
```bash
git clone <repository-url>
cd workflow_delegacion_sintesis_streamlit
```

2. **Crear entorno virtual**
```bash
python -m venv .venv
source .venv/bin/activate  # En Windows: .venv\Scripts\activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Configurar variables de entorno**

Crear un archivo `.env` en la raÃ­z del proyecto:
```env
GOOGLE_API_KEY=tu_google_api_key
COHERE_API_KEY=tu_cohere_api_key
```

## ğŸ—ï¸ Estructura del Proyecto

```
workflow_delegacion_sintesis_streamlit/
â”œâ”€â”€ app.py                      # Interfaz Streamlit (Frontend)
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ config.py              # ConfiguraciÃ³n de LLM y embeddings
â”‚   â”œâ”€â”€ graph.py               # ConstrucciÃ³n del grafo LangGraph
â”‚   â”œâ”€â”€ nodes.py               # LÃ³gica de los nodos del grafo
â”‚   â”œâ”€â”€ state.py               # DefiniciÃ³n del estado
â”‚   â”œâ”€â”€ supervisor.py          # Modelo de decisiÃ³n del supervisor
â”‚   â”œâ”€â”€ specialists.py         # Agentes especializados
â”‚   â””â”€â”€ tools/
â”‚       â””â”€â”€ rag_tools.py       # Herramientas de bÃºsqueda RAG
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ ingestion.py           # Procesamiento de documentos
â”œâ”€â”€ .env                       # Variables de entorno (no versionado)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ¯ Uso

1. **Iniciar la aplicaciÃ³n**
```bash
streamlit run app.py
```

2. **Cargar documentos**
   - Selecciona el tipo de documento (`documento_01` o `documento_02`)
   - Sube un archivo PDF
   - Ajusta los parÃ¡metros de chunking si es necesario
   - Haz clic en "Procesar Documento"

3. **Hacer consultas**
   - Escribe tu pregunta en el chat
   - El sistema enrutarÃ¡ automÃ¡ticamente tu consulta al agente especializado correcto
   - Recibe respuestas basadas en el contenido de los documentos

## ğŸ”§ TecnologÃ­as Utilizadas

- **Frontend**: Streamlit
- **LLM**: Google Gemini 2.5 Flash
- **Embeddings**: Cohere (embed-english-light-v3.0)
- **Vector Store**: FAISS
- **Framework de Agentes**: LangGraph
- **Procesamiento de PDFs**: PyPDF

## ğŸ“ ConfiguraciÃ³n Avanzada

### ParÃ¡metros de Chunking

- **TamaÃ±o del Chunk**: 100-6000 caracteres (default: 500)
- **Solapamiento**: 0-2000 caracteres (default: 125)

Ajusta estos valores segÃºn la naturaleza de tus documentos para optimizar la recuperaciÃ³n de informaciÃ³n.

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor, abre un issue primero para discutir los cambios que te gustarÃ­a realizar.

## ğŸ“„ Licencia

Este proyecto es de uso educativo.
